{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd74233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:54:32.981897Z",
     "iopub.status.busy": "2025-02-05T08:54:32.981528Z",
     "iopub.status.idle": "2025-02-05T08:54:32.988528Z",
     "shell.execute_reply": "2025-02-05T08:54:32.987968Z"
    },
    "papermill": {
     "duration": 0.015406,
     "end_time": "2025-02-05T08:54:32.990097",
     "exception": false,
     "start_time": "2025-02-05T08:54:32.974691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deps_path = '/kaggle/input/czii-cryoet-dependencies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9ac862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:54:33.000269Z",
     "iopub.status.busy": "2025-02-05T08:54:33.000058Z",
     "iopub.status.idle": "2025-02-05T08:54:34.047389Z",
     "shell.execute_reply": "2025-02-05T08:54:34.046444Z"
    },
    "papermill": {
     "duration": 1.054547,
     "end_time": "2025-02-05T08:54:34.049429",
     "exception": false,
     "start_time": "2025-02-05T08:54:32.994882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cp -r /kaggle/input/czii-cryoet-dependencies/asciitree-0.3.3/ asciitree-0.3.3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e5db28",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-02-05T08:54:34.061302Z",
     "iopub.status.busy": "2025-02-05T08:54:34.061011Z",
     "iopub.status.idle": "2025-02-05T08:55:16.236165Z",
     "shell.execute_reply": "2025-02-05T08:55:16.235162Z"
    },
    "papermill": {
     "duration": 42.183974,
     "end_time": "2025-02-05T08:55:16.238312",
     "exception": false,
     "start_time": "2025-02-05T08:54:34.054338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./asciitree-0.3.3/asciitree-0.3.3\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: asciitree\r\n",
      "  Building wheel for asciitree (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5034 sha256=9187800ad11e4c3249fbd9ab598786d547af0ff351558238d1b040560ceae9af\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/df/a8/c6318c87827b53ea48635bf95b1249186d3d21f041176e062e\r\n",
      "Successfully built asciitree\r\n"
     ]
    }
   ],
   "source": [
    "! pip wheel asciitree-0.3.3/asciitree-0.3.3/\n",
    "! cp /kaggle/input/best-weights-code/* ./ -r\n",
    "! cp /kaggle/input/best-weights ./ -r\n",
    "! cp /kaggle/input/voxhrnet-v2/voxhrnetV2.py ./ -r\n",
    "! cp /kaggle/input/load-vox-net/load_model.py ./ -r\n",
    "! cp /kaggle/input/hrnet-v1/* ./ -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62358bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:55:16.249943Z",
     "iopub.status.busy": "2025-02-05T08:55:16.249344Z",
     "iopub.status.idle": "2025-02-05T08:55:22.270740Z",
     "shell.execute_reply": "2025-02-05T08:55:22.269635Z"
    },
    "papermill": {
     "duration": 6.029577,
     "end_time": "2025-02-05T08:55:22.272983",
     "exception": false,
     "start_time": "2025-02-05T08:55:16.243406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cp /kaggle/input/d/luoziqian/unet2e3d-6c/* ./\n",
    "! cp /kaggle/input/voxhrnet/voxhrnet.py ./ -r\n",
    "! cp /kaggle/input/vox-networks-dataset/voxhrnet.py ./\n",
    "! cp /kaggle/input/vox-networks-dataset/config_small.yaml ./\n",
    "! cp /kaggle/input/vox-networks-dataset/model10.py ./\n",
    "! cp /kaggle/input/voxresnet-v0/voxresnetV0.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53883485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:55:22.285279Z",
     "iopub.status.busy": "2025-02-05T08:55:22.284499Z",
     "iopub.status.idle": "2025-02-05T08:56:43.007849Z",
     "shell.execute_reply": "2025-02-05T08:56:43.006897Z"
    },
    "papermill": {
     "duration": 80.732141,
     "end_time": "2025-02-05T08:56:43.010445",
     "exception": false,
     "start_time": "2025-02-05T08:55:22.278304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./asciitree-0.3.3-py3-none-any.whl\r\n",
      "Installing collected packages: asciitree\r\n",
      "Successfully installed asciitree-0.3.3\r\n",
      "Processing /kaggle/input/einops-0-8-none-any/einops-0.8.0-py3-none-any.whl\r\n",
      "Installing collected packages: einops\r\n",
      "Successfully installed einops-0.8.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install asciitree-0.3.3-py3-none-any.whl\n",
    "! pip install /kaggle/input/einops-0-8-none-any/einops-0.8.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1c9bba",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-02-05T08:56:43.022607Z",
     "iopub.status.busy": "2025-02-05T08:56:43.021988Z",
     "iopub.status.idle": "2025-02-05T08:57:01.305556Z",
     "shell.execute_reply": "2025-02-05T08:57:01.304681Z"
    },
    "papermill": {
     "duration": 18.291836,
     "end_time": "2025-02-05T08:57:01.307736",
     "exception": false,
     "start_time": "2025-02-05T08:56:43.015900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "dask-expr 1.1.15 requires dask==2024.9.1, but you have dask 2024.11.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\r\n",
      "rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.11.0 which is incompatible.\r\n",
      "rapids-dask-dependency 24.8.0a0 requires distributed==2024.7.1, but you have distributed 2024.11.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -q --no-index --find-links {deps_path} --requirement {deps_path}/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce8d2cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:57:01.320090Z",
     "iopub.status.busy": "2025-02-05T08:57:01.319462Z",
     "iopub.status.idle": "2025-02-05T08:57:41.916956Z",
     "shell.execute_reply": "2025-02-05T08:57:41.915882Z"
    },
    "papermill": {
     "duration": 40.606247,
     "end_time": "2025-02-05T08:57:41.919499",
     "exception": false,
     "start_time": "2025-02-05T08:57:01.313252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/vox-networks-dataset/yacs-0.1.8-py3-none-any.whl\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from yacs==0.1.8) (6.0.2)\r\n",
      "Installing collected packages: yacs\r\n",
      "Successfully installed yacs-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "! pip install /kaggle/input/vox-networks-dataset/yacs-0.1.8-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8669bdc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:57:41.931679Z",
     "iopub.status.busy": "2025-02-05T08:57:41.931366Z",
     "iopub.status.idle": "2025-02-05T08:58:17.205682Z",
     "shell.execute_reply": "2025-02-05T08:58:17.204973Z"
    },
    "papermill": {
     "duration": 35.282589,
     "end_time": "2025-02-05T08:58:17.207721",
     "exception": false,
     "start_time": "2025-02-05T08:57:41.925132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "from monai.data import DataLoader, Dataset, CacheDataset, decollate_batch\n",
    "from monai.transforms import (\n",
    "    Compose, \n",
    "    EnsureChannelFirstd, \n",
    "    Orientationd,  \n",
    "    AsDiscrete,  \n",
    "    RandFlipd, \n",
    "    RandRotate90d, \n",
    "    NormalizeIntensityd,\n",
    "    RandCropByLabelClassesd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19849509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:58:17.220016Z",
     "iopub.status.busy": "2025-02-05T08:58:17.219276Z",
     "iopub.status.idle": "2025-02-05T08:58:17.307053Z",
     "shell.execute_reply": "2025-02-05T08:58:17.306305Z"
    },
    "papermill": {
     "duration": 0.095525,
     "end_time": "2025-02-05T08:58:17.308689",
     "exception": false,
     "start_time": "2025-02-05T08:58:17.213164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandShiftIntensityd,\n",
    "    RandRotate90d,\n",
    ")\n",
    "from monai.data import (\n",
    "    ThreadDataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    "    set_track_meta,\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceCELoss\n",
    "import torch\n",
    "import einops\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7a6ec",
   "metadata": {
    "papermill": {
     "duration": 0.004912,
     "end_time": "2025-02-05T08:58:17.318964",
     "exception": false,
     "start_time": "2025-02-05T08:58:17.314052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define some helper functions\n",
    "\n",
    "\n",
    "### Patching helper functions\n",
    "\n",
    "These are mostly used to split large volumes into smaller ones and stitch them back together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d023777e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:58:17.330249Z",
     "iopub.status.busy": "2025-02-05T08:58:17.329978Z",
     "iopub.status.idle": "2025-02-05T08:58:17.338004Z",
     "shell.execute_reply": "2025-02-05T08:58:17.337352Z"
    },
    "papermill": {
     "duration": 0.015581,
     "end_time": "2025-02-05T08:58:17.339512",
     "exception": false,
     "start_time": "2025-02-05T08:58:17.323931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_patch_starts_with_overlap(\n",
    "    dimension_size: int, patch_size: int, overlap: int\n",
    ") -> List[int]:\n",
    "    if dimension_size <= patch_size:\n",
    "        return [0]\n",
    "\n",
    "    num_patches = np.ceil(\n",
    "        (dimension_size - overlap) / (patch_size - overlap) + 1\n",
    "    ).astype(int)\n",
    "    patch_starts = []\n",
    "    for i in range(num_patches):\n",
    "        pos = int(i * (patch_size - overlap))\n",
    "        if pos + patch_size > dimension_size:\n",
    "            pos = dimension_size - patch_size\n",
    "        if pos not in patch_starts:\n",
    "            patch_starts.append(pos)\n",
    "    return patch_starts\n",
    "\n",
    "\n",
    "def extract_3d_patches_overlap(\n",
    "    arrays: List[np.ndarray],\n",
    "    patch_sizes: Tuple[int, int, int],\n",
    "    overlap_sizes: Tuple[int, int, int],\n",
    ") -> Tuple[List[np.ndarray], List[Tuple[int, int, int]]]:\n",
    "\n",
    "    patch_starts_x = calculate_patch_starts_with_overlap(\n",
    "        arrays[0].shape[0], patch_sizes[0], overlap_sizes[0]\n",
    "    )\n",
    "    patch_starts_y = calculate_patch_starts_with_overlap(\n",
    "        arrays[0].shape[1], patch_sizes[1], overlap_sizes[1]\n",
    "    )\n",
    "    patch_starts_z = calculate_patch_starts_with_overlap(\n",
    "        arrays[0].shape[2], patch_sizes[2], overlap_sizes[2]\n",
    "    )\n",
    "    patch_size_d, patch_size_h, patch_size_w = patch_sizes\n",
    "    patches = []\n",
    "    coordinates = []\n",
    "    for arr in arrays:\n",
    "        for x in patch_starts_x:\n",
    "            for y in patch_starts_y:\n",
    "                for z in patch_starts_z:\n",
    "                    patch = arr[\n",
    "                        x : x + patch_size_d, y : y + patch_size_h, z : z + patch_size_w\n",
    "                    ]\n",
    "                    patches.append(patch)\n",
    "                    coordinates.append((x, y, z))\n",
    "\n",
    "    return patches, coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506a386",
   "metadata": {
    "papermill": {
     "duration": 0.004794,
     "end_time": "2025-02-05T08:58:17.349409",
     "exception": false,
     "start_time": "2025-02-05T08:58:17.344615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee75a63b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:58:17.360297Z",
     "iopub.status.busy": "2025-02-05T08:58:17.360051Z",
     "iopub.status.idle": "2025-02-05T08:58:17.363557Z",
     "shell.execute_reply": "2025-02-05T08:58:17.362793Z"
    },
    "papermill": {
     "duration": 0.010926,
     "end_time": "2025-02-05T08:58:17.365274",
     "exception": false,
     "start_time": "2025-02-05T08:58:17.354348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = \"/kaggle/input/create-numpy-dataset-exp-name\"\n",
    "TEST_DATA_DIR = \"/kaggle/input/czii-cryo-et-object-identification\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd85099",
   "metadata": {
    "papermill": {
     "duration": 0.004773,
     "end_time": "2025-02-05T08:58:17.375151",
     "exception": false,
     "start_time": "2025-02-05T08:58:17.370378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initialize the model\n",
    "\n",
    "This model is pretty much directly copied from [3D U-Net PyTorch Lightning distributed training](https://www.kaggle.com/code/zhuowenzhao11/3d-u-net-pytorch-lightning-distributed-training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf899de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:58:17.386042Z",
     "iopub.status.busy": "2025-02-05T08:58:17.385798Z",
     "iopub.status.idle": "2025-02-05T08:58:17.389264Z",
     "shell.execute_reply": "2025-02-05T08:58:17.388460Z"
    },
    "papermill": {
     "duration": 0.010685,
     "end_time": "2025-02-05T08:58:17.390790",
     "exception": false,
     "start_time": "2025-02-05T08:58:17.380105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules import Module\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77da8fb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:58:17.402106Z",
     "iopub.status.busy": "2025-02-05T08:58:17.401865Z",
     "iopub.status.idle": "2025-02-05T08:58:18.442427Z",
     "shell.execute_reply": "2025-02-05T08:58:18.441230Z"
    },
    "papermill": {
     "duration": 1.048596,
     "end_time": "2025-02-05T08:58:18.444552",
     "exception": false,
     "start_time": "2025-02-05T08:58:17.395956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/unet2d3e/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecafb99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:58:18.456820Z",
     "iopub.status.busy": "2025-02-05T08:58:18.456495Z",
     "iopub.status.idle": "2025-02-05T08:58:18.932482Z",
     "shell.execute_reply": "2025-02-05T08:58:18.931818Z"
    },
    "papermill": {
     "duration": 0.484393,
     "end_time": "2025-02-05T08:58:18.934457",
     "exception": false,
     "start_time": "2025-02-05T08:58:18.450064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import TverskyLoss\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "# use warmup lr scheduler\n",
    "from torch.optim.lr_scheduler import (\n",
    "    CosineAnnealingLR,\n",
    "    CosineAnnealingWarmRestarts,\n",
    "    StepLR,\n",
    ")\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from monai.networks.nets import UNet, AttentionUnet\n",
    "from monai.losses import TverskyLoss\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "# use warmup lr scheduler\n",
    "from torch.optim.lr_scheduler import (\n",
    "    CosineAnnealingLR,\n",
    "    CosineAnnealingWarmRestarts,\n",
    "    StepLR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d50941c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:58:18.946374Z",
     "iopub.status.busy": "2025-02-05T08:58:18.945901Z",
     "iopub.status.idle": "2025-02-05T08:58:18.950556Z",
     "shell.execute_reply": "2025-02-05T08:58:18.949913Z"
    },
    "papermill": {
     "duration": 0.01215,
     "end_time": "2025-02-05T08:58:18.952140",
     "exception": false,
     "start_time": "2025-02-05T08:58:18.939990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_v2 = {\n",
    "    \"MODEL\": {\n",
    "        \"NAME\": \"voxhrnet\",\n",
    "        \"EXTRA\": {\n",
    "            \"STAGE2\": {\n",
    "                \"NUM_MODULES\": 1,\n",
    "                \"NUM_BRANCHES\": 2,\n",
    "                \"BLOCK\": \"BASIC\",\n",
    "                \"NUM_BLOCKS\": [3, 3],\n",
    "                \"NUM_CHANNELS\": [16, 32],\n",
    "            },\n",
    "            \"STAGE3\": {\n",
    "                \"NUM_MODULES\": 1,\n",
    "                \"NUM_BRANCHES\": 3,\n",
    "                \"BLOCK\": \"BASIC\",\n",
    "                \"NUM_BLOCKS\": [3, 3, 3],\n",
    "                \"NUM_CHANNELS\": [16, 32, 64],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b4b6108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:58:18.963434Z",
     "iopub.status.busy": "2025-02-05T08:58:18.963215Z",
     "iopub.status.idle": "2025-02-05T08:58:20.867243Z",
     "shell.execute_reply": "2025-02-05T08:58:20.866587Z"
    },
    "papermill": {
     "duration": 1.912174,
     "end_time": "2025-02-05T08:58:20.869320",
     "exception": false,
     "start_time": "2025-02-05T08:58:18.957146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet,SegResNet,DynUNet\n",
    "from custom_vnet import CustomVNet\n",
    "from model2_6c import Net\n",
    "# from voxhrnet import build_model\n",
    "from voxhrnetV2 import build_model as build_model_v2\n",
    "from load_model import build_model as build_model_v3\n",
    "from model10_v1 import build_model as build_model_v4\n",
    "from voxresnetV0 import VoxResNet as VoxResNetV0\n",
    "\n",
    "basic_unet = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(48, 64, 80, 80),\n",
    "    strides=(2, 2, 1),\n",
    "    num_res_units=1,\n",
    ")\n",
    "basic_unet_1 = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(48, 64, 80, 80),\n",
    "    strides=(2, 2, 1),\n",
    "    num_res_units=2,\n",
    ")\n",
    "basic_unet_6c = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=6,\n",
    "    channels=(48, 64, 80, 80),\n",
    "    strides=(2, 2, 1),\n",
    "    num_res_units=1,\n",
    ")\n",
    "\n",
    "segresnet_6c_v1 = SegResNet(\n",
    "    in_channels=1,\n",
    "    out_channels=6,\n",
    "    dropout_prob=0.1,\n",
    "    upsample_mode=\"deconv\",\n",
    ")\n",
    "\n",
    "basic_unet2e3d = Net(\n",
    "    out_channels=7,\n",
    "    arch=\"resnet18d\",\n",
    "    decoder_dim=[80, 80, 64, 32, 16],\n",
    "    pretrained=False,\n",
    ")\n",
    "\n",
    "basic_dynunet_v1 = DynUNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=6,\n",
    "    kernel_size=(3, 3, 3, 3),\n",
    "    strides=((1, 1, 1), 2, 2, 1),\n",
    "    upsample_kernel_size=(2, 2, 1),\n",
    "    filters=[16, 24, 48, 80, 80],\n",
    "    norm_name=\"instance\",\n",
    "    act_name=\"PRELU\",\n",
    "    deep_supervision=True,\n",
    ")\n",
    "\n",
    "basic_dynunet_v1 = DynUNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=6,\n",
    "    kernel_size=(3, 3, 3, 3),\n",
    "    strides=((1, 1, 1), 2, 2, 1),\n",
    "    upsample_kernel_size=(2, 2, 1),\n",
    "    filters=[16, 24, 48, 80, 80],\n",
    "    norm_name=\"instance\",\n",
    "    act_name=\"PRELU\",\n",
    "    deep_supervision=True,\n",
    ")\n",
    "\n",
    "basic_dynunet_v2 = DynUNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=6,\n",
    "    kernel_size=(3, 3, 3, 3, 3),\n",
    "    strides=((1, 1, 1), 2, 2, 2, 1),\n",
    "    upsample_kernel_size=(2, 2, 2, 1),\n",
    "    filters=[16, 24, 48, 80, 80],\n",
    "    norm_name=\"instance\",\n",
    "    act_name=\"PRELU\",\n",
    "    deep_supervision=True,\n",
    ")\n",
    "\n",
    "# basic_voxhrnet_v0 = build_model(1,6)\n",
    "basic_voxhrnet_v2 = build_model_v2(1,6,config_v2)\n",
    "basic_voxhrnet_v3 = build_model_v3()\n",
    "bisic_voxhrnet_v4 = build_model_v4()\n",
    "\n",
    "basic_voxresnet_v0 = VoxResNetV0(in_channels=1, n_classes=7)\n",
    "\n",
    "basic_dense_vnet = CustomVNet(in_channels=1, classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "406e2eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:58:20.881434Z",
     "iopub.status.busy": "2025-02-05T08:58:20.881183Z",
     "iopub.status.idle": "2025-02-05T08:58:20.886292Z",
     "shell.execute_reply": "2025-02-05T08:58:20.885653Z"
    },
    "papermill": {
     "duration": 0.012915,
     "end_time": "2025-02-05T08:58:20.887911",
     "exception": false,
     "start_time": "2025-02-05T08:58:20.874996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "best_weights_dir = \"best-weights\"\n",
    "os.listdir(best_weights_dir)\n",
    "# best_weights_path_list = [\n",
    "#  'best-weights/epoch122-step2952-valid_loss0.3625-val_metric0.8367.ckpt',\n",
    "#  'best-weights/epoch148-step3576-valid_loss1.1154-val_metric0.7722.ckpt',\n",
    "#  'best-weights/epoch153-step3696-valid_loss0.3021-val_metric0.8900.ckpt',\n",
    "#  'best-weights/epoch194-step4680-valid_loss1.0213-val_metric0.8788.ckpt',\n",
    "#  '/kaggle/input/voxresnet-v0/epoch195-step4704-valid_loss0.4258-val_metric0.7914.ckpt',\n",
    "# ] \\\n",
    "#  + ['/kaggle/input/hrnet-v1/epoch188-step4536-valid_loss0.4231-val_metric0.8659.ckpt'] \\\n",
    "#  + ['/kaggle/input/unet2e3d-6c/pytorch/default/1/unet2E3D-v1-epoch114-val_loss0.55-val_metric0.53-step2760.ckpt'] \\\n",
    "#  + ['/kaggle/input/my-weights/unet3D-epoch173-val_loss0.53-val_metric0.54-step4176.ckpt']  \\\n",
    "#  + ['best-weights/epoch152-step3672-valid_loss0.4333-val_metric0.7929.ckpt'] \\\n",
    "#  +['/kaggle/input/segresnet-6c/pytorch/default/1/epoch314-val_loss0.54-val_metric0.54-step7560.ckpt']\n",
    "\n",
    "#  # + ['/kaggle/input/hrnet-v1/epoch188-step4536-valid_loss0.4231-val_metric0.8659.ckpt'] \n",
    "\n",
    "\n",
    " # +['/kaggle/input/my-weights/unet3D-epoch173-val_loss0.53-val_metric0.54-step4176.ckpt']\n",
    "\n",
    "\n",
    "\n",
    " # +['/kaggle/input/segresnet-6c/pytorch/default/1/epoch314-val_loss0.54-val_metric0.54-step7560.ckpt']\n",
    "\n",
    "#  + ['/kaggle/input/dynunet-6c/pytorch/default/1/DynUnet-epoch189-val_loss0.51-val_metric0.55-step4560.ckpt'] \\\n",
    "#  +['/kaggle/input/segresnet-6c/pytorch/default/1/epoch314-val_loss0.54-val_metric0.54-step7560.ckpt']\n",
    "\n",
    "#  +['/kaggle/input/my-weights/unet3D-epoch173-val_loss0.53-val_metric0.54-step4176.ckpt']\n",
    " # +['/kaggle/input/unet2e3d-6c/pytorch/default/1/unet2E3D-v1-epoch114-val_loss0.55-val_metric0.53-step2760.ckpt'] \\\n",
    "# best_weights_path_list=['/kaggle/input/dynunet-6c/pytorch/default/1/DynUnet-epoch189-val_loss0.51-val_metric0.55-step4560.ckpt']\n",
    "# best_weights_path_list=['/kaggle/input/dynunet-6c/pytorch/default/2/DynUnet-v2-epoch164-val_loss0.53-val_metric0.53-step3960.ckpt']\n",
    "# best_weights_path_list=['/kaggle/input/vox-networks-dataset/epoch133-step3216-valid_loss0.4223-val_metric0.8612.ckpt']\n",
    "best_weights_path_list = ['/kaggle/input/unet2e3d-7c/pytorch/default/1/unet2e3d-epoch135-step3264-valid_loss0.4315-val_metric0.7775.ckpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc304d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T08:58:20.899595Z",
     "iopub.status.busy": "2025-02-05T08:58:20.899366Z",
     "iopub.status.idle": "2025-02-05T08:58:24.861328Z",
     "shell.execute_reply": "2025-02-05T08:58:24.860645Z"
    },
    "papermill": {
     "duration": 3.970319,
     "end_time": "2025-02-05T08:58:24.863355",
     "exception": false,
     "start_time": "2025-02-05T08:58:20.893036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load unet2e3d\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "dummy_input = torch.rand((1, 1, 128, 384, 384)).half().cuda()\n",
    "\n",
    "model_list = []\n",
    "for idx,path in enumerate(best_weights_path_list):\n",
    "    ckpt = torch.load(path)\n",
    "    state_dict_ = ckpt[\"state_dict\"]\n",
    "    state_dict = {}\n",
    "    for k in state_dict_.keys():\n",
    "        if \"model.\" in k:\n",
    "            state_dict[k[6:]] = state_dict_[k]\n",
    "    try:\n",
    "        model = copy.deepcopy(basic_unet)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load unet\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_unet.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(basic_unet_1)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load unet_1\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_unet_1.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        # print(\"load failed\")\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(basic_dense_vnet)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load vnet\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_vnet.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        # print(\"load failed\")\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(basic_unet_6c)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load unet_6c\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_unet_6c.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        # print(\"load failed\")\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(basic_unet2e3d)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load unet2e3d\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_unet2e3d.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        # print(\"load failed\")\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(segresnet_6c_v1)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load segresnet_6c_v1\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_segresnet_6c_v1.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        # print(\"load failed\")\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(basic_dynunet_v1)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load dynunet\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_dynunet.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        # print(\"load failed\")\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(basic_dynunet_v2)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load basic_dynunet_v2\")  \n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_basic_dynunet_v2.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        # print(\"load failed\")\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(basic_voxhrnet_v0)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load basic_voxhrnet_v0\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_basic_voxhrnet_v0.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(basic_voxhrnet_v3)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load basic_voxhrnet_v3\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_basic_voxhrnet_v3.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(bisic_voxhrnet_v4)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load bisic_voxhrnet_v4\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_bisic_voxhrnet_v4.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(basic_voxhrnet_v2)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load basic_voxhrnet_v2\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_basic_voxhrnet_v2.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model = copy.deepcopy(basic_voxresnet_v0)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model_list.append(model.to(\"cpu\"))\n",
    "        print(\"load basic_voxresnet_v0\")\n",
    "        model=model.eval().half().cuda()\n",
    "        dynamic_axes = {\"images\": {0: \"batch\"}, \"output\": {0: \"batch\"}}\n",
    "        output_name=f\"{idx}_basic_voxresnet_v0.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            output_name,\n",
    "            verbose=False,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=12        \n",
    "        )\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe2466",
   "metadata": {
    "papermill": {
     "duration": 0.005059,
     "end_time": "2025-02-05T08:58:24.873995",
     "exception": false,
     "start_time": "2025-02-05T08:58:24.868936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10033515,
     "sourceId": 84969,
     "sourceType": "competition"
    },
    {
     "datasetId": 6052780,
     "sourceId": 9862305,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6040935,
     "sourceId": 9867543,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6058495,
     "sourceId": 9869730,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6233973,
     "sourceId": 10106143,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6383310,
     "sourceId": 10364147,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6512054,
     "sourceId": 10522003,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6513752,
     "sourceId": 10524633,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6528712,
     "sourceId": 10551753,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6509390,
     "sourceId": 10573055,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6552409,
     "sourceId": 10587481,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6554845,
     "sourceId": 10591029,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6557851,
     "sourceId": 10595206,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6557884,
     "sourceId": 10595259,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6572779,
     "sourceId": 10616474,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6576941,
     "sourceId": 10622345,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6603433,
     "sourceId": 10662702,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 206640467,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 213055282,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 215061124,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 198599,
     "modelInstanceId": 176271,
     "sourceId": 208471,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 198200,
     "modelInstanceId": 175864,
     "sourceId": 208598,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 186240,
     "modelInstanceId": 163890,
     "sourceId": 208866,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 198200,
     "modelInstanceId": 175864,
     "sourceId": 209184,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 198599,
     "modelInstanceId": 176271,
     "sourceId": 209261,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 202595,
     "modelInstanceId": 180333,
     "sourceId": 211515,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 186240,
     "modelInstanceId": 180111,
     "sourceId": 221414,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 224862,
     "modelInstanceId": 203128,
     "sourceId": 237845,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 225518,
     "modelInstanceId": 203787,
     "sourceId": 238613,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 227328,
     "modelInstanceId": 205581,
     "sourceId": 240586,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 228293,
     "modelInstanceId": 206545,
     "sourceId": 241798,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 228293,
     "modelInstanceId": 206545,
     "sourceId": 242194,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 229084,
     "modelInstanceId": 207362,
     "sourceId": 242790,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 229084,
     "modelInstanceId": 207362,
     "sourceId": 243128,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 235824,
     "modelInstanceId": 214151,
     "sourceId": 250544,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 237.733216,
   "end_time": "2025-02-05T08:58:28.250032",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-05T08:54:30.516816",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
